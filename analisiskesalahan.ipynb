{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c97991",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The tokenizer you are loading from './best_fold_model_minilm' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data terbaca       : 2040\n",
      "Total salah prediksi     : 584\n",
      "Contoh yang ditampilkan  : 3\n",
      "\n",
      "[1] Q: Gimana cara saya lihat transkrip nilai?\n",
      "    True: prosedur_akses_cetak_transkrip_nilai\n",
      "    Pred: prosedur_pengajuan_legalisir_transkrip_nilai (conf=0.0565)\n",
      "------------------------------------------------------------\n",
      "[2] Q: Bagaimana proses lengkap pengajuan hingga pelaksanaan program magang bagi mahasiswa TI Unpad?\n",
      "    True: alur_pengajuan_dan_pelaksanaan_program_magang_hingga_selesai\n",
      "    Pred: prosedur_pengajuan_program_magang (conf=0.0402)\n",
      "------------------------------------------------------------\n",
      "[3] Q: Bagaimana cara mengetahui apakah pembayaran UKT sudah berhasil atau belum?\n",
      "    True: prosedur_cek_status_pembayaran_ukt\n",
      "    Pred: konsekuensi_tidak_bayar_ukt_tepat_waktu (conf=0.0387)\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# AMBIL CONTOH SALAH PREDIKSI DARI MODEL YANG SUDAH DISIMPAN\n",
    "# ============================================================\n",
    "\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# ============================================================\n",
    "# KONFIGURASI PATH\n",
    "# ============================================================\n",
    "\n",
    "# Folder model kamu (isi: model.safetensors, config.json, vocab.txt, dst)\n",
    "MODEL_DIR = \"./best_fold_model_minilm\"\n",
    "\n",
    "DATA_PATH = \"./dataset_chatbot.json\"\n",
    "\n",
    "# File label_names\n",
    "LABEL_FILE = os.path.join(MODEL_DIR, \"label_names.json\")\n",
    "\n",
    "# Berapa contoh salah prediksi yang mau ditampilkan\n",
    "MAX_EXAMPLES = 3\n",
    "\n",
    "# Panjang max token\n",
    "MAX_LENGTH = 64\n",
    "\n",
    "# ============================================================\n",
    "# LOAD DEVICE\n",
    "# ============================================================\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ============================================================\n",
    "# LOAD TOKENIZER & MODEL\n",
    "# ============================================================\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR).to(device)\n",
    "model.eval()\n",
    "\n",
    "# ============================================================\n",
    "# LOAD LABEL MAPPING\n",
    "# ============================================================\n",
    "\n",
    "# Fungsi bantu: baca label_names.json\n",
    "def load_label_names(path: str) -> List[str]:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # label_names.json kamu bisa bentuk:\n",
    "    # 1) list: [\"intent_a\", \"intent_b\", ...]\n",
    "    # 2) dict: {\"0\":\"intent_a\",\"1\":\"intent_b\"} atau {\"intent_a\":0,...}\n",
    "    if isinstance(data, list):\n",
    "        return data\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        # kalau key-nya angka (string) -> urutkan berdasarkan id\n",
    "        if all(str(k).isdigit() for k in data.keys()):\n",
    "            return [data[str(i)] for i in sorted(map(int, data.keys()))]\n",
    "\n",
    "        # kalau key-nya nama label -> balik mapping\n",
    "        # urutkan berdasarkan id\n",
    "        if all(isinstance(v, int) for v in data.values()):\n",
    "            inv = {v: k for k, v in data.items()}\n",
    "            return [inv[i] for i in sorted(inv.keys())]\n",
    "\n",
    "    raise ValueError(\"Format label_names.json tidak dikenali.\")\n",
    "\n",
    "# Ambil label list dari file, kalau tidak ada -> pakai label2id dari config model\n",
    "if os.path.exists(LABEL_FILE):\n",
    "    label_list = load_label_names(LABEL_FILE)\n",
    "else:\n",
    "    # fallback: ambil dari config\n",
    "    # (biasanya config.id2label ada)\n",
    "    id2label = model.config.id2label\n",
    "    if isinstance(id2label, dict) and len(id2label) > 0:\n",
    "        # id2label sering key-nya string angka\n",
    "        label_list = [id2label[str(i)] if str(i) in id2label else id2label[i] for i in range(len(id2label))]\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Tidak menemukan label_names.json dan config model tidak punya id2label.\")\n",
    "\n",
    "label2id = {label: idx for idx, label in enumerate(label_list)}\n",
    "\n",
    "# ============================================================\n",
    "# LOAD DATASET JSON\n",
    "# ============================================================\n",
    "\n",
    "with open(DATA_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "# dataset harus list of dict\n",
    "if not isinstance(dataset, list):\n",
    "    raise ValueError(\"Dataset JSON harus berupa list of objects.\")\n",
    "\n",
    "# Fungsi bantu untuk ambil field pertanyaan dan intent\n",
    "def get_field(item: Dict[str, Any], keys: List[str]) -> Any:\n",
    "    for k in keys:\n",
    "        if k in item and item[k] is not None:\n",
    "            return item[k]\n",
    "    return None\n",
    "\n",
    "# ============================================================\n",
    "# INFERENCE + AMBIL YANG SALAH PREDIKSI\n",
    "# ============================================================\n",
    "\n",
    "wrong_cases = []\n",
    "\n",
    "for item in dataset:\n",
    "    # Ambil pertanyaan\n",
    "    question = get_field(item, [\"question\", \"pertanyaan\", \"Pertanyaan\"])\n",
    "    # Ambil label asli\n",
    "    true_intent = get_field(item, [\"intent\", \"Intent\", \"label\"])\n",
    "\n",
    "    # Skip kalau data tidak lengkap\n",
    "    if not question or not true_intent:\n",
    "        continue\n",
    "\n",
    "    # Kalau intent di dataset tidak ada di label model, skip (biar tidak error)\n",
    "    if true_intent not in label2id:\n",
    "        continue\n",
    "\n",
    "    # Tokenisasi\n",
    "    enc = tokenizer(\n",
    "        str(question),\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=MAX_LENGTH,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    # Pindah ke device\n",
    "    enc = {k: v.to(device) for k, v in enc.items()}\n",
    "\n",
    "    # Prediksi\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**enc)\n",
    "        logits = outputs.logits.squeeze(0)              # shape: [num_labels]\n",
    "        probs = F.softmax(logits, dim=-1)               # probability tiap label\n",
    "        pred_id = int(torch.argmax(probs).item())\n",
    "        pred_intent = label_list[pred_id]\n",
    "        conf = float(probs[pred_id].item())\n",
    "\n",
    "    # Bandingkan\n",
    "    if pred_intent != true_intent:\n",
    "        wrong_cases.append({\n",
    "            \"question\": question,\n",
    "            \"true_intent\": true_intent,\n",
    "            \"pred_intent\": pred_intent,\n",
    "            \"confidence\": round(conf, 4)\n",
    "        })\n",
    "\n",
    "# Urutkan: yang paling yakin tapi salah (menarik untuk analisis)\n",
    "wrong_cases.sort(key=lambda x: x[\"confidence\"], reverse=True)\n",
    "\n",
    "unique_examples = []\n",
    "seen_pred = set()\n",
    "\n",
    "for ex in wrong_cases:\n",
    "    # pastikan pred_intent belum pernah muncul\n",
    "    if ex[\"pred_intent\"] in seen_pred:\n",
    "        continue\n",
    "\n",
    "    unique_examples.append(ex)\n",
    "    seen_pred.add(ex[\"pred_intent\"])\n",
    "\n",
    "    if len(unique_examples) >= MAX_EXAMPLES:\n",
    "        break\n",
    "\n",
    "examples = unique_examples\n",
    "\n",
    "# ============================================================\n",
    "# TAMPILKAN DI TERMINAL\n",
    "# ============================================================\n",
    "\n",
    "print(f\"Total data terbaca       : {len(dataset)}\")\n",
    "print(f\"Total salah prediksi     : {len(wrong_cases)}\")\n",
    "print(f\"Contoh yang ditampilkan  : {len(examples)}\\n\")\n",
    "\n",
    "for i, ex in enumerate(examples, 1):\n",
    "    print(f\"[{i}] Q: {ex['question']}\")\n",
    "    print(f\"    True: {ex['true_intent']}\")\n",
    "    print(f\"    Pred: {ex['pred_intent']} (conf={ex['confidence']})\")\n",
    "    print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75ebd3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data terbaca       : 2040\n",
      "Total salah prediksi     : 27\n",
      "Contoh yang ditampilkan  : 3\n",
      "\n",
      "[1] Q: LiVE Unpad itu bisa dipakai buat ngapain aja?\n",
      "    True: info_fitur_platform_elearning\n",
      "    Pred: info_akses_lms_mobile (conf=0.7648)\n",
      "------------------------------------------------------------\n",
      "[2] Q: Cara bayar UKT lewat mana aja?\n",
      "    True: info_metode_pembayaran_ukt\n",
      "    Pred: prosedur_pembayaran_ukt (conf=0.7426)\n",
      "------------------------------------------------------------\n",
      "[3] Q: Repository Tugas Akhir itu apa sih?\n",
      "    True: info_repository_tugas_akhir\n",
      "    Pred: info_durasi_akses_repository_tugas_akhir (conf=0.7248)\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# AMBIL CONTOH SALAH PREDIKSI DARI MODEL YANG SUDAH DISIMPAN\n",
    "# (tanpa retraining)\n",
    "# ============================================================\n",
    "\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# ============================================================\n",
    "# KONFIGURASI PATH\n",
    "# ============================================================\n",
    "\n",
    "# Folder model kamu (isi: model.safetensors, config.json, vocab.txt, dst)\n",
    "MODEL_DIR = \"./best_fold_model_indobert\"\n",
    "\n",
    "DATA_PATH = \"./dataset_chatbot.json\" \n",
    "\n",
    "# File label_names\n",
    "LABEL_FILE = os.path.join(MODEL_DIR, \"label_names.json\")\n",
    "\n",
    "\n",
    "# Berapa contoh salah prediksi yang mau ditampilkan\n",
    "MAX_EXAMPLES = 3\n",
    "\n",
    "# Panjang max token\n",
    "MAX_LENGTH = 64\n",
    "\n",
    "# ============================================================\n",
    "# LOAD DEVICE\n",
    "# ============================================================\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ============================================================\n",
    "# LOAD TOKENIZER & MODEL\n",
    "# ============================================================\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR).to(device)\n",
    "model.eval()\n",
    "\n",
    "# ============================================================\n",
    "# LOAD LABEL MAPPING\n",
    "# ============================================================\n",
    "\n",
    "# Fungsi bantu: baca label_names.json\n",
    "def load_label_names(path: str) -> List[str]:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # label_names.json kamu bisa bentuk:\n",
    "    # 1) list: [\"intent_a\", \"intent_b\", ...]\n",
    "    # 2) dict: {\"0\":\"intent_a\",\"1\":\"intent_b\"} atau {\"intent_a\":0,...}\n",
    "    if isinstance(data, list):\n",
    "        return data\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        # kalau key-nya angka (string) -> urutkan berdasarkan id\n",
    "        if all(str(k).isdigit() for k in data.keys()):\n",
    "            return [data[str(i)] for i in sorted(map(int, data.keys()))]\n",
    "\n",
    "        # kalau key-nya nama label -> balik mapping\n",
    "        # urutkan berdasarkan id\n",
    "        if all(isinstance(v, int) for v in data.values()):\n",
    "            inv = {v: k for k, v in data.items()}\n",
    "            return [inv[i] for i in sorted(inv.keys())]\n",
    "\n",
    "    raise ValueError(\"Format label_names.json tidak dikenali.\")\n",
    "\n",
    "# Ambil label list dari file, kalau tidak ada -> pakai label2id dari config model\n",
    "if os.path.exists(LABEL_FILE):\n",
    "    label_list = load_label_names(LABEL_FILE)\n",
    "else:\n",
    "    # fallback: ambil dari config\n",
    "    # (biasanya config.id2label ada)\n",
    "    id2label = model.config.id2label\n",
    "    if isinstance(id2label, dict) and len(id2label) > 0:\n",
    "        # id2label sering key-nya string angka\n",
    "        label_list = [id2label[str(i)] if str(i) in id2label else id2label[i] for i in range(len(id2label))]\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Tidak menemukan label_names.json dan config model tidak punya id2label.\")\n",
    "\n",
    "label2id = {label: idx for idx, label in enumerate(label_list)}\n",
    "\n",
    "# ============================================================\n",
    "# LOAD DATASET JSON\n",
    "# ============================================================\n",
    "\n",
    "with open(DATA_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "# dataset harus list of dict\n",
    "if not isinstance(dataset, list):\n",
    "    raise ValueError(\"Dataset JSON harus berupa list of objects.\")\n",
    "\n",
    "# Fungsi bantu untuk ambil field pertanyaan dan intent\n",
    "def get_field(item: Dict[str, Any], keys: List[str]) -> Any:\n",
    "    for k in keys:\n",
    "        if k in item and item[k] is not None:\n",
    "            return item[k]\n",
    "    return None\n",
    "\n",
    "# ============================================================\n",
    "# INFERENCE + AMBIL YANG SALAH PREDIKSI\n",
    "# ============================================================\n",
    "\n",
    "wrong_cases = []\n",
    "\n",
    "for item in dataset:\n",
    "    # Ambil pertanyaan\n",
    "    question = get_field(item, [\"question\", \"pertanyaan\", \"Pertanyaan\"])\n",
    "    # Ambil label asli\n",
    "    true_intent = get_field(item, [\"intent\", \"Intent\", \"label\"])\n",
    "\n",
    "    # Skip kalau data tidak lengkap\n",
    "    if not question or not true_intent:\n",
    "        continue\n",
    "\n",
    "    # Kalau intent di dataset tidak ada di label model, skip (biar tidak error)\n",
    "    if true_intent not in label2id:\n",
    "        continue\n",
    "\n",
    "    # Tokenisasi\n",
    "    enc = tokenizer(\n",
    "        str(question),\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=MAX_LENGTH,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    # Pindah ke device\n",
    "    enc = {k: v.to(device) for k, v in enc.items()}\n",
    "\n",
    "    # Prediksi\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**enc)\n",
    "        logits = outputs.logits.squeeze(0)              # shape: [num_labels]\n",
    "        probs = F.softmax(logits, dim=-1)               # probability tiap label\n",
    "        pred_id = int(torch.argmax(probs).item())\n",
    "        pred_intent = label_list[pred_id]\n",
    "        conf = float(probs[pred_id].item())\n",
    "\n",
    "    # Bandingkan\n",
    "    if pred_intent != true_intent:\n",
    "        wrong_cases.append({\n",
    "            \"question\": question,\n",
    "            \"true_intent\": true_intent,\n",
    "            \"pred_intent\": pred_intent,\n",
    "            \"confidence\": round(conf, 4)\n",
    "        })\n",
    "\n",
    "# Urutkan: yang paling yakin tapi salah (menarik untuk analisis)\n",
    "wrong_cases.sort(key=lambda x: x[\"confidence\"], reverse=True)\n",
    "\n",
    "# Ambil contoh secukupnya\n",
    "examples = wrong_cases[:MAX_EXAMPLES]\n",
    "\n",
    "# ============================================================\n",
    "# TAMPILKAN DI TERMINAL\n",
    "# ============================================================\n",
    "\n",
    "print(f\"Total data terbaca       : {len(dataset)}\")\n",
    "print(f\"Total salah prediksi     : {len(wrong_cases)}\")\n",
    "print(f\"Contoh yang ditampilkan  : {len(examples)}\\n\")\n",
    "\n",
    "for i, ex in enumerate(examples, 1):\n",
    "    print(f\"[{i}] Q: {ex['question']}\")\n",
    "    print(f\"    True: {ex['true_intent']}\")\n",
    "    print(f\"    Pred: {ex['pred_intent']} (conf={ex['confidence']})\")\n",
    "    print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "369dc533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== CONFIDENCE THRESHOLD ANALYSIS =====\n",
      "Total data dianalisis : 2040\n",
      "\n",
      "Confidence Range | Total | Wrong | Error Rate\n",
      "-------------------------------------------------------\n",
      "0.60-0.69       |    14 |     1 | 7.14%\n",
      "0.70-0.79       |    32 |     3 | 9.38%\n",
      ">=0.80          |  1919 |     0 | 0.00%\n",
      "-------------------------------------------------------\n",
      "\n",
      "Fallback Rate per Threshold\n",
      "Threshold | Fallback Count | Fallback Rate\n",
      "-------------------------------------------------------\n",
      "0.6       |             66 | 3.24%\n",
      "0.7       |             81 | 3.97%\n",
      "0.8       |            121 | 5.93%\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CONFIDENCE THRESHOLD ANALYSIS\n",
    "# Menghitung error rate dan fallback rate berdasarkan confidence\n",
    "# ============================================================\n",
    "# Mengimpor library json untuk membaca file JSON\n",
    "import json\n",
    "# Mengimpor library os untuk pengelolaan path file\n",
    "import os\n",
    "# Mengimpor defaultdict untuk inisialisasi dictionary otomatis\n",
    "from collections import defaultdict\n",
    "# Mengimpor type hint untuk kejelasan struktur data\n",
    "from typing import List, Dict, Any\n",
    "# Mengimpor library PyTorch\n",
    "import torch\n",
    "# Mengimpor fungsi softmax dari PyTorch\n",
    "import torch.nn.functional as F\n",
    "# Mengimpor tokenizer dan model dari HuggingFace Transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# ============================================================\n",
    "# KONFIGURASI\n",
    "# ============================================================\n",
    "MODEL_DIR = \"./best_fold_model_indobert\"\n",
    "DATA_PATH = \"./dataset_chatbot.json\"\n",
    "# Menentukan path file mapping label\n",
    "LABEL_FILE = os.path.join(MODEL_DIR, \"label_names.json\")\n",
    "# Menentukan panjang maksimum token input\n",
    "MAX_LENGTH = 64\n",
    "# Menentukan rentang confidence untuk analisis error rate\n",
    "CONFIDENCE_BINS = [\n",
    "    (0.60, 0.69),   # Rentang confidence rendah\n",
    "    (0.70, 0.79),   # Rentang confidence menengah\n",
    "    (0.80, 1.00),   # Rentang confidence tinggi\n",
    "]\n",
    "# Menentukan threshold confidence yang dianalisis fallback-nya\n",
    "THRESHOLDS = [0.6,0.7, 0.8]\n",
    "# ============================================================\n",
    "# DEVICE\n",
    "# ============================================================\n",
    "# Menentukan device (GPU jika tersedia, jika tidak CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# ============================================================\n",
    "# LOAD MODEL & TOKENIZER\n",
    "# ============================================================\n",
    "# Memuat tokenizer berdasarkan direktori model\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\n",
    "# Memuat model klasifikasi dan memindahkannya ke device\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR).to(device)\n",
    "# Mengatur model ke mode evaluasi\n",
    "model.eval()\n",
    "# ============================================================\n",
    "# LOAD LABEL NAMES\n",
    "# ============================================================\n",
    "# Fungsi untuk memuat daftar label dari file JSON\n",
    "def load_label_names(path: str) -> List[str]:\n",
    "    # Membuka file label_names.json\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Jika format berupa list\n",
    "    if isinstance(data, list):\n",
    "        return data\n",
    "\n",
    "    # Jika format berupa dictionary\n",
    "    if isinstance(data, dict):\n",
    "        # Jika key berupa angka (string)\n",
    "        if all(str(k).isdigit() for k in data.keys()):\n",
    "            return [data[str(i)] for i in sorted(map(int, data.keys()))]\n",
    "\n",
    "        # Jika value berupa integer (id label)\n",
    "        if all(isinstance(v, int) for v in data.values()):\n",
    "            inv = {v: k for k, v in data.items()}\n",
    "            return [inv[i] for i in sorted(inv.keys())]\n",
    "\n",
    "    # Error jika format tidak dikenali\n",
    "    raise ValueError(\"Format label_names.json tidak dikenali.\")\n",
    "\n",
    "# Mengecek apakah file label tersedia\n",
    "if os.path.exists(LABEL_FILE):\n",
    "    # Memuat label dari file\n",
    "    label_list = load_label_names(LABEL_FILE)\n",
    "else:\n",
    "    # Mengambil label dari konfigurasi model\n",
    "    id2label = model.config.id2label\n",
    "    label_list = [id2label[str(i)] for i in range(len(id2label))]\n",
    "\n",
    "# Membuat mapping dari label ke id\n",
    "label2id = {label: idx for idx, label in enumerate(label_list)}\n",
    "\n",
    "# ============================================================\n",
    "# LOAD DATASET\n",
    "# ============================================================\n",
    "\n",
    "# Membuka file dataset JSON\n",
    "with open(DATA_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "# Fungsi untuk mengambil field dengan beberapa kemungkinan nama\n",
    "def get_field(item: Dict[str, Any], keys: List[str]) -> Any:\n",
    "    # Iterasi setiap kemungkinan nama field\n",
    "    for k in keys:\n",
    "        # Mengembalikan nilai jika field ditemukan dan tidak None\n",
    "        if k in item and item[k] is not None:\n",
    "            return item[k]\n",
    "    # Mengembalikan None jika tidak ditemukan\n",
    "    return None\n",
    "\n",
    "# ============================================================\n",
    "# INFERENSI & SIMPAN HASIL\n",
    "# ============================================================\n",
    "\n",
    "# List untuk menyimpan hasil prediksi\n",
    "results = []\n",
    "\n",
    "# Iterasi setiap data pada dataset\n",
    "for item in dataset:\n",
    "    # Mengambil teks pertanyaan\n",
    "    question = get_field(item, [\"question\", \"pertanyaan\", \"Pertanyaan\"])\n",
    "\n",
    "    # Mengambil label asli\n",
    "    true_intent = get_field(item, [\"intent\", \"Intent\", \"label\"])\n",
    "\n",
    "    # Melewati data jika tidak lengkap\n",
    "    if not question or not true_intent:\n",
    "        continue\n",
    "\n",
    "    # Melewati data jika label tidak dikenali model\n",
    "    if true_intent not in label2id:\n",
    "        continue\n",
    "\n",
    "    # Melakukan tokenisasi teks pertanyaan\n",
    "    enc = tokenizer(\n",
    "        str(question),\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=MAX_LENGTH,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    # Memindahkan tensor ke device\n",
    "    enc = {k: v.to(device) for k, v in enc.items()}\n",
    "\n",
    "    # Melakukan inferensi tanpa gradien\n",
    "    with torch.no_grad():\n",
    "        # Menghasilkan output model\n",
    "        outputs = model(**enc)\n",
    "\n",
    "        # Mengambil logits hasil klasifikasi\n",
    "        logits = outputs.logits.squeeze(0)\n",
    "\n",
    "        # Menghitung probabilitas dengan softmax\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "        # Mengambil indeks label dengan probabilitas tertinggi\n",
    "        pred_id = int(torch.argmax(probs).item())\n",
    "\n",
    "        # Mengambil nama intent hasil prediksi\n",
    "        pred_intent = label_list[pred_id]\n",
    "\n",
    "        # Mengambil confidence prediksi\n",
    "        confidence = float(probs[pred_id].item())\n",
    "\n",
    "    # Menyimpan hasil confidence dan kebenaran prediksi\n",
    "    results.append({\n",
    "        \"confidence\": confidence,\n",
    "        \"correct\": pred_intent == true_intent\n",
    "    })\n",
    "\n",
    "# Menghitung total data yang dianalisis\n",
    "total_data = len(results)\n",
    "\n",
    "# ============================================================\n",
    "# ERROR RATE PER RENTANG CONFIDENCE\n",
    "# ============================================================\n",
    "\n",
    "# Dictionary untuk menyimpan statistik error per rentang\n",
    "bin_stats = defaultdict(lambda: {\"total\": 0, \"wrong\": 0})\n",
    "\n",
    "# Iterasi setiap hasil prediksi\n",
    "for r in results:\n",
    "    # Mengambil nilai confidence\n",
    "    conf = r[\"confidence\"]\n",
    "\n",
    "    # Menentukan rentang confidence\n",
    "    for low, high in CONFIDENCE_BINS:\n",
    "        if low <= conf <= high:\n",
    "            # Menentukan label rentang\n",
    "            key = f\"{low:.2f}-{high:.2f}\" if high < 1.0 else \">=0.80\"\n",
    "\n",
    "            # Menambah jumlah data pada rentang tersebut\n",
    "            bin_stats[key][\"total\"] += 1\n",
    "\n",
    "            # Menambah jumlah salah prediksi jika tidak benar\n",
    "            if not r[\"correct\"]:\n",
    "                bin_stats[key][\"wrong\"] += 1\n",
    "\n",
    "# ============================================================\n",
    "# FALLBACK RATE PER THRESHOLD\n",
    "# ============================================================\n",
    "\n",
    "# Dictionary untuk menyimpan statistik fallback\n",
    "fallback_stats = {}\n",
    "\n",
    "# Iterasi setiap threshold\n",
    "for t in THRESHOLDS:\n",
    "    # Menghitung jumlah data dengan confidence di bawah threshold\n",
    "    fallback_count = sum(1 for r in results if r[\"confidence\"] < t)\n",
    "\n",
    "    # Menghitung fallback rate\n",
    "    fallback_rate = fallback_count / total_data if total_data > 0 else 0.0\n",
    "\n",
    "    # Menyimpan hasil fallback\n",
    "    fallback_stats[t] = {\n",
    "        \"count\": fallback_count,\n",
    "        \"rate\": fallback_rate\n",
    "    }\n",
    "\n",
    "# ============================================================\n",
    "# TAMPILKAN HASIL\n",
    "# ============================================================\n",
    "\n",
    "# Menampilkan judul analisis\n",
    "print(\"\\n===== CONFIDENCE THRESHOLD ANALYSIS =====\")\n",
    "\n",
    "# Menampilkan total data yang dianalisis\n",
    "print(f\"Total data dianalisis : {total_data}\\n\")\n",
    "\n",
    "# Menampilkan header tabel error rate\n",
    "print(\"Confidence Range | Total | Wrong | Error Rate\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# Menampilkan hasil error rate per rentang\n",
    "for key in [\"0.60-0.69\", \"0.70-0.79\", \">=0.80\"]:\n",
    "    stat = bin_stats.get(key, {\"total\": 0, \"wrong\": 0})\n",
    "    total = stat[\"total\"]\n",
    "    wrong = stat[\"wrong\"]\n",
    "    error_rate = (wrong / total) if total > 0 else 0.0\n",
    "    print(f\"{key:15} | {total:5} | {wrong:5} | {error_rate:.2%}\")\n",
    "\n",
    "# Garis pemisah\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# Menampilkan header tabel fallback rate\n",
    "print(\"\\nFallback Rate per Threshold\")\n",
    "print(\"Threshold | Fallback Count | Fallback Rate\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# Menampilkan hasil fallback rate\n",
    "for t in THRESHOLDS:\n",
    "    fs = fallback_stats[t]\n",
    "    print(f\"{t:<9} | {fs['count']:14} | {fs['rate']:.2%}\")\n",
    "\n",
    "# Garis penutup\n",
    "print(\"-\" * 55)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
